{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Parameter Estimation\n",
        "## Maximum Likelihood Estimation (MLE)\n",
        "### Algorithm\n",
        "<ol>\n",
        "  <li> Decide on a model for the distribution of your samples. Define the PMF/PDF for your sample </li>\n",
        "  <li> Write out the log likelihood function. </li>\n",
        "  <li> State that the optimal parameters are the argmax of the log likelihood function. </li>\n",
        "  <li> Use an optimization algorithm to calculate argmax </li>\n",
        "</ol>\n",
        "\n",
        "### Maximum Likelihood\n",
        "Likelihood:\n",
        "$$ L(\\theta) = \\prod_{i = 1}^nf(X_i\\,|\\,\\theta) $$\n",
        "Log Likelihood:\n",
        "$$ LL(\\theta) = \\sum_{i = 1}^n\\log{f(X_i\\,|\\,\\theta)} $$\n",
        "Parameter:\n",
        "$$ \\hat{\\theta} = \\textrm{argmax}_\\theta LL(\\theta) $$\n",
        "\n",
        "### How do you compute $\\textrm{argmax}$?\n",
        "\n",
        "#### Computation using calculus\n",
        "$$\\hat{x}  = \\textrm{arg max}_x f(x)$$\n",
        "This can be done by finding the value of $x$ where the derivative vanishes.\n",
        "$$ \\textrm{Suppose } f(x) = -x^2 + 4, \\qquad\\textrm{where }-2 < x < 2$$\n",
        "$$ \\frac{d}{dx}f(x) = \\frac{d}{dx}(-x^2 + 4) = -2x$$\n",
        "\n",
        "### Example: MLE for Poisson\n",
        "Suppose we have 12 data points, $X_1, ..., X_n$, each of them an IID sampled from an unknown Poisson distribution, that is:\n",
        "* $X_i \\sim Poi(\\lambda)$\n",
        "* PMF can be written as: $f(x_i\\,|\\,\\lambda) = \\frac{e^{-\\lambda}\\lambda^{x_i}}{x_i!}$\n",
        "* Likelihood: $L(\\lambda) = f(x_1, ..., x_n\\,|\\,\\lambda) = \\prod_{i = 1}^{n}f(x_i\\,|\\,\\lambda) = \\prod_{i = 1}^n\\frac{e^{-\\lambda}\\lambda^{x_i}}{x_i!}$\n",
        "* Log Likelihood: $LL(\\lambda) = \\log \\prod_{i = 1}^n\\frac{e^{-\\lambda}\\lambda^{x_i}}{x_i!} = \\sum_{i = 1}^n \\log \\frac{e^{-\\lambda}\\lambda^{x_i}}{x_i!} = \\sum_{i = 1}^n -\\lambda + x_i\\log \\lambda - \\log x_i! $\n",
        "Now, we are left with the task to find the $\\textrm{arg max}$ of our log likelihood.\n",
        "* Differentiate with respect to $\\lambda$ and set to 0:\n",
        "$$\\frac{\\partial LL(\\lambda)}{\\partial \\lambda} = 0 = -n + \\frac{1}{\\lambda}\\sum_{i = 1}^nx_i$$\n",
        "\n",
        "Which gives:\n",
        "$$\\lambda = \\frac{1}{n}\\sum_{i = 1}^nx_i$$\n",
        "\n",
        "This is rather frustrating, as we did an entire page worth of mathematics to come to the simple result that the MLE of Poisson is the mean of all the data points.\n",
        "\n",
        "### Example: MLE for Bernoulli\n",
        "Just a disclaimer, that the PMF of Bernoulli is not differentiable. There arises a need to redefine the bernoulli such that it can be differentiated to calculate the MLE.\n",
        "$$f(x_i\\,|\\,p) = p^{x_i}(1-p)^{1-x_i} $$\n",
        "If we were to apply the math once again, we would end up at the result:\n",
        "$$p_{_{MLE}} = \\frac{1}{n}\\sum_{i = 1}^nX_i$$\n",
        "This is also the sample mean of our distribution.\n",
        "\n",
        "### Maximum Likelihood with Gaussian\n",
        "Consider a sample of n iid random variables $X_1, X_2, X_3, ..., X_n$\n",
        "* Let $X_i \\sim \\mathcal{N}(\\mu, \\sigma^2)$\n",
        "* $f(X_i\\,|\\,\\mu,\\,\\sigma^2) = \\frac{1}{\\sqrt{2\\pi}\\sigma}e^{-\\frac{(X_i - \\mu)^2}{2\\sigma^2}}$\n",
        "If we were to calculate, again, we would have the following:\n",
        "$$\\mu_{_{MLE}} = \\frac{1}{n}\\sum_{i = 1}^nX_i$$\n",
        "$$\\sigma^2_{_{MLE}} = \\frac{1}{n}\\sum_{i = 1}^n(X_i - \\mu_{_{MLE}})^2 $$\n",
        "So, it is pretty reasonable that the MLE of the mean was the sample mean, however, it is also noticable that the MLE of the variance isn't the sample variance. Therefore, we say that the MLE of the variance is biased based on data."
      ],
      "metadata": {
        "id": "3G25qmPFboFH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Gradient Ascent\n",
        "$$\\theta_j^{\\textrm{ new}} = \\theta_j^{\\textrm{ old}} + \\eta \\cdotp \\frac{\\partial LL(\\theta^{\\textrm{ old}})}{\\partial \\theta_j^{\\textrm{ old}}}$$\n",
        "Here, $\\eta$ is supposed to be the Step Size Constant, or the Learning Rate. Note that in this algorithm, we're finding the $\\textrm{argmax}$ of the likelihood function, that is, we want the parameters at the highest value of our likelihood function.\\\n",
        "If we were implementing something like linear regression, we would want the learning rate constant to be negative (or add a -ve sign before it), and practice something known as **Gradient Descent**, where we would want the difference between the actual value, and our estimated value (the error) to be the smallest.\\\n",
        "Another thing we could do is calculate the parameters at minima using gradient descent **of the negative log likelihood function**."
      ],
      "metadata": {
        "id": "IoGFKebqkYT0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## MLE could Benefit from Priors\n",
        "Consider iid random variables $X_1, X_2, ..., X_n$.\n",
        "* $X_i \\sim Uni(0, 1)$\n",
        "* Observe Data:\n",
        "  * 0.15, 0.20, 0.30, 0.40, 0.65, 0.70, 0.75\n",
        "\n",
        "The problem with MLE is that it overfits. Overfitting means that the parameters you choose describe your dataset too well, which means it has very strict constraints on what does and doesn't constitute. In the above case, it predicts the $\\alpha$ and $\\beta$ of the uniformly distributed data to be 0.15 and 0.75 respectively.\\\n",
        "To combat this, we could use Bayesian Probability. We could have a really strong belief before we start looking at the data. This is the same as using a $\\beta$ distribution of priors, before we start seeing the data.\n",
        "\n",
        "## Maximum A Posteriori\n",
        "$$\\hat{\\theta}_{_{MAP}} = \\textrm{argmax}_\\theta f(\\Theta = \\theta\\,|\\,X^{(1)} = x^{(1)}, ..., X^{(n)} = x^{(n)})$$\n",
        "Instead of choosing the parameters which make the data more likely, MAP chooses parameters that are more likely, given the value of the data.\n",
        "$$\\hat{\\theta}_{_{MAP}} = \\textrm{argmax}_\\theta f(x^{(1)}, ..., x^{(n)}\\,|\\,\\theta)g(\\theta)$$\n",
        "$$ = \\textrm{argmax}_\\theta\\,g(\\theta)\\prod_{i = 1}^nf(x^{(i)}\\,|\\,\\theta)$$\n",
        "$$ \\hat{\\theta}_{_{MAP}} = \\textrm{argmax}_\\theta\\,\\left(\\log(g(\\theta)) + \\sum_{i = 1}^n\\log(f(x^{(i)}\\,|\\,\\theta))\\right)$$"
      ],
      "metadata": {
        "id": "C6h5I3v0svip"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We have different distributions that we use as priors for other different distributions. The goal is to find a distribution that is a conjugate, so we can add our findings into the prior without having to get an entirely new function for the posterior.\n",
        "### Quick MAP for Bernoulli\n",
        "$Beta(a, b)$ is a conjugate prior for the probability of success in Bernoulli and Binomial Distributions.\\\n",
        "* Prior: $Beta(a,b)$\n",
        "* Experiment: Observe $n + m$ new trials: $n$ successes and $m$ failures.\n",
        "* Posterior: $Beta(a + n, b + m)$\n",
        "* MAP(the mode of the posterior): $p = \\frac{a+n-1}{a+b+n+m-2}$\n",
        "\n",
        "One estimate is to have one success and one failure added with the actual data. This is known as the laplace prior.\n",
        "\n",
        "### Brute force Bayes Classifier\n",
        "$$\\hat{y} = \\textrm{arg max}_{y = \\{0, 1\\}}P(y | x)$$"
      ],
      "metadata": {
        "id": "8DBV3Bf-WNNX"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "amXLnCYtblGJ"
      },
      "outputs": [],
      "source": []
    }
  ]
}