{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "authorship_tag": "ABX9TyOhjUycjLLG6CBiKDSKAfcR"
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import scipy"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-08T07:37:51.860480Z",
     "start_time": "2024-03-08T07:37:51.857389Z"
    }
   },
   "execution_count": 13
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Binomial Distribution\n",
    "## Formula\n",
    "$$ P_x = \\left(^{n}_k\\right) p^xq^{n-x}$$\n",
    "Here, \\\n",
    "$P$ = binomial probability \\\n",
    "$x$ = number of times a specific outcome within n trials \\\n",
    "$\\left(^n_x\\right)$ = number of combinations \\\n",
    "$p$ = Probability of success in a single trial \\\n",
    "$q$ = Probability of failure in a single trial \\\n",
    "$n$ = Number of trials"
   ],
   "metadata": {
    "id": "qXRYujHKA6_H"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Example 1\n",
    "1000 ads are served, each clicked with $p = 0.01$, otherwise ignored. What is the probability of 10 clicks or less?"
   ],
   "metadata": {
    "id": "AqNgLUM2Cl8V"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# For 10 clicks or less, we first need to understand that p(10 clicks exactly) = Value at 10 in the binomial distribution of 1000 clicks of 0.01 probability.\n",
    "# Then, we run a loop\n",
    "totalProbability = 0\n",
    "for i in range(1, 11):\n",
    "  totalProbability += scipy.stats.binom.pmf(i, 1000, 0.01)\n",
    "totalProbability"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xnpgSK0jC23h",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1709697191619,
     "user_tz": -330,
     "elapsed": 784,
     "user": {
      "displayName": "Parshv Joshi",
      "userId": "11339326919544553803"
     }
    },
    "outputId": "06b91776-c075-4902-a9ee-b4197f60ac58",
    "ExecuteTime": {
     "end_time": "2024-03-08T07:37:54.075913Z",
     "start_time": "2024-03-08T07:37:53.426857Z"
    }
   },
   "execution_count": 14,
   "outputs": [
    {
     "data": {
      "text/plain": "0.5829976320536874"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Example 2\n",
    "A program is run $7$ times, each run crashes with a probability of $0.3$, what is the chance of exactly 3 crashes?"
   ],
   "metadata": {
    "id": "P9uIsdAlGHFZ"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Again, we use scipy's binomial distribution function\n",
    "scipy.stats.binom.pmf(3, 7, 0.3)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "p_vlkOKwGTDo",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1709697191619,
     "user_tz": -330,
     "elapsed": 6,
     "user": {
      "displayName": "Parshv Joshi",
      "userId": "11339326919544553803"
     }
    },
    "outputId": "71a523a6-4184-4b2a-ba7b-67589c8f4989",
    "ExecuteTime": {
     "end_time": "2024-03-08T07:37:55.426088Z",
     "start_time": "2024-03-08T07:37:55.420739Z"
    }
   },
   "execution_count": 15,
   "outputs": [
    {
     "data": {
      "text/plain": "0.22689449999999992"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Example 3\n",
    "An NBA series is a seven-game series. You win the seven-game series if you win **at least** four of the seven matches. The task is to calculate the probability of winning the series, given the probability of winning each game is $0.55$, and each game being independent of the other."
   ],
   "metadata": {
    "id": "PEd0BrgwHXGP"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# We use a loop, along with pmf, to calculate\n",
    "totalProbability = 0\n",
    "for i in range(4, 8):\n",
    "  totalProbability += scipy.stats.binom.pmf(i, 7, 0.55)\n",
    "totalProbability"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0bbzFAUgHw_z",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1709697191619,
     "user_tz": -330,
     "elapsed": 5,
     "user": {
      "displayName": "Parshv Joshi",
      "userId": "11339326919544553803"
     }
    },
    "outputId": "0b7cd51f-0ff2-47e8-ba05-98725d49a3e7",
    "ExecuteTime": {
     "end_time": "2024-03-08T07:37:56.575197Z",
     "start_time": "2024-03-08T07:37:56.571253Z"
    }
   },
   "execution_count": 16,
   "outputs": [
    {
     "data": {
      "text/plain": "0.608287796875"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Bernoulli Random Variable\n",
    "A special case of the Binary Random Variable where the number of events is $1$. This can either result in a success or a failure. Given the probability of a random event succeeding being $p$:\n",
    "$$P(X=1) = p$$\n",
    "$$P(X=0) = 1-p$$\n",
    "Where, X is a Bernoulli random variable.\n",
    "$$E[x] = p$$\n",
    "\n",
    "## Expectation of Binomial\n",
    "\n",
    "We have an underlying formula that relates Binomial RV with Bernoulli Rv.\n",
    "$$X = \\sum_{i=1}^{n}Y_i$$\n",
    "Where, $X$ is the Binomial RV, and $Y_i$ is the Bernoulli RV.\n",
    "Since $E[Y_i] = p$\n",
    "\n",
    "$$ E[X] = \\sum_{i=1}^{n}E[Y_i] $$\n",
    "$$ = np $$"
   ],
   "metadata": {
    "id": "_OUFMnX_Jtej"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Variance\n",
    "If $X$ is a random variable with mean $\\mu$, then the **variance** of X, denoted by $Var(X)$, is:\n",
    "$$Var(X) = E[(X-\\mu)^2]$$\n",
    "Variance is a formal term for the spread of a random variable, also known as the **2nd central moment**.\n",
    "\n",
    "$$Var(X) = \\sum_{x} (x-\\mu)^2p(x)$$\n",
    "$$ = E[X^2]-(E[X])^2 $$\n",
    "\n",
    "The square root of the variance is known as the **standard deviation**."
   ],
   "metadata": {
    "id": "KeKPSijjOEOA"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Poisson\n",
    "\n",
    "## Starting with a problem\n",
    "Suppose we want to derive an algorithm for cab pooling. For that, we need an important metric. Given the number of average requests per minute from an area, i.e. $\\lambda$, I want the probability of exactly $k$ requests coming in from the area in the next minute.\n",
    "\n",
    "Our first intuition, binomial, doesn't work. Because we don't have discretized time slots. But what if we make the time slots discretized.\n",
    "Suppose we divide the next minute into $n$ sections. Then, the probability of a request occuring in each of the $n$ sections is $\\frac{\\lambda}{n}$. Now, we use the binomial distribution as follows:\n",
    "$$P(X = k) = \\left(^n_k\\right)\\left(\\frac{\\lambda}{n}\\right)^k\\left(1-\\left(\\frac{\\lambda}{n}\\right)\\right)^{n-k}$$\n",
    "When n tends to infinity, this becomes more and more accurate. To do this, we use the fact that when $n\\rightarrow\\infty$, $\\left(1-\\left(\\frac{\\lambda}{n}\\right)\\right)^n = e^{-\\lambda}$ along with some limit simplification to get:\n",
    "$$P(X = k) = \\frac{\\lambda ^k e^{-\\lambda}}{k!}$$\n",
    "\n",
    "This is known as the **Poisson Random Variable**,\n",
    "$$X = ~Poi(\\lambda)$$\n",
    "This is cool because it takes in only the average number of events in a given time period, and tells us the probability of some number of events within that same time period."
   ],
   "metadata": {
    "id": "098wv4ZvRIis"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Example 1\n",
    "Given that a region experienes an average of 2.79 major earthquakes per year, what is the probability of 3 major earthquakes next year?"
   ],
   "metadata": {
    "id": "CyKDUPgZlOWW"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# We use scipy's poisson pmf to calculate the value\n",
    "scipy.stats.poisson.pmf(3, 2.79)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-ImoW23OlNBR",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1709697191619,
     "user_tz": -330,
     "elapsed": 4,
     "user": {
      "displayName": "Parshv Joshi",
      "userId": "11339326919544553803"
     }
    },
    "outputId": "f9050ee9-455c-45be-f7e5-2e1d3a8e4037",
    "ExecuteTime": {
     "end_time": "2024-03-08T07:37:57.385887Z",
     "start_time": "2024-03-08T07:37:57.380986Z"
    }
   },
   "execution_count": 17,
   "outputs": [
    {
     "data": {
      "text/plain": "0.22232062512462486"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Poisson to approximate a binomial\n",
    "\n",
    "Other than the obvious application of poisson in probability, because we derived poisson by using a limit of $n\\rightarrow\\infty$, we sometimes also use poisson to approximate the binomial given the condition that $n$ is very large."
   ],
   "metadata": {
    "id": "iBGznHKHmWZe"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Example\n",
    "<ul>\n",
    "  <li>In DNA (and real networks), data is stored as large strings.</li>\n",
    "  <li>The length of a sequence is in the order of $10^4$. </li>\n",
    "  <li>The probability of corruption of each base pair is very small. $p \\approx 10^{-6}$</li>\n",
    "</ul>\n",
    "Thus, to compute the probability that $1\\%$ of the data is corrupted, we have to compute $X \\sim Bin(10^4, 10^{-6})$, which is a rather unwieldy computation."
   ],
   "metadata": {
    "id": "f0T18SugmzC3"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We choose:\n",
    "$$X \\sim Poi(\\lambda = 10^4Â·10^{-6} = 0.01)$$\n",
    "\n",
    "Therefore,\n",
    "$$ P(X = k) = e^{-\\lambda}\\frac{\\lambda ^k}{k!}$$\n",
    "We can use this to calculate the probability of zero corruptions, say:\n",
    "$$ P(X = 0) = e^{-\\lambda}\\frac{1}{0!}$$"
   ],
   "metadata": {
    "id": "LBsvRk5EoFdo"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### When can this approximation be used?\n",
    "This can be used when $n$ is large, $p$ is small, and $n\\cdotp p$ is moderate.\n"
   ],
   "metadata": {
    "id": "xTqfuZw3o_eO"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Variance of the Poisson\n",
    "Recall: $Y \\sim Bin(n, p)$ \\\\\n",
    "<ul>\n",
    "  <li> $E[Y] = np$ </li>\n",
    "  <li> $Var(Y) = np(1-p)$ </li>\n",
    "</ul>\n",
    "\n",
    "Now, for a poisson distribution:\n",
    "$$ X \\sim Poi(\\lambda) \\qquad  \\textrm{ where, } \\lambda = n\\cdotp p \\left(n \\rightarrow \\infty, p \\rightarrow 0 \\right)$$\n",
    "<ul>\n",
    "  <li> $E[X] = n\\cdotp p = \\lambda$ </li>\n",
    "  <li> $Var(X) = np(1-p) = \\lambda (1-0) = \\lambda$ </li>\n",
    "</ul>\n"
   ],
   "metadata": {
    "id": "zghZkF-ZqtHd"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Example: Web Server Load\n",
    "Consider requests to a web server in 1 second.\n",
    "<ul>\n",
    "  <li> In past, server load averages 2 hits/second. </li>\n",
    "  <li> $X = \\#$ hits server receives in a second. </li>\n",
    "  <li> What is $P(X < 5)$ </li>\n",
    "</ul>"
   ],
   "metadata": {
    "id": "jQh8T0d8tafn"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# We can use the poisson to solve this. We just calculate the probability of 1 through 4 hits individually, and then just add up the probability, as the events are mutually exclusive\n",
    "probabilityCount = 0\n",
    "for i in range(1, 5):\n",
    "  probabilityCount += scipy.stats.poisson.pmf(i, 2)\n",
    "probabilityCount"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OPJAtlRXnwN5",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1709697191620,
     "user_tz": -330,
     "elapsed": 4,
     "user": {
      "displayName": "Parshv Joshi",
      "userId": "11339326919544553803"
     }
    },
    "outputId": "0ddeb5fd-3851-4be3-ccd4-377e4f0e4671",
    "ExecuteTime": {
     "end_time": "2024-03-08T07:37:58.570157Z",
     "start_time": "2024-03-08T07:37:58.566353Z"
    }
   },
   "execution_count": 18,
   "outputs": [
    {
     "data": {
      "text/plain": "0.8120116994196761"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Geometric Random Variable\n",
    "$X$ is a **Geometric** Random Variable: $X \\sim Geo(p)$\n",
    "<ul>\n",
    "  <li> $X$ is number of independent trials until first success. </li>\n",
    "  <li> $p$ is probability of success on each trial. </li>\n",
    "  <li> $X$ takes on values $1, 2, 3, ...,$ with probability: </li>\n",
    "</ul>\n",
    "\n",
    "With this, we can derive the probability mass function with a simple thought experiment. We can say the probability of generating the output after $X=n$ trials means that exactly $n-1$ times, we need the probability of not getting success, and then after they have occured, we need success exactly one time.\n",
    "Therefore:\n",
    "$$P(X = n) = (1-p)^{n-1}p$$\n",
    "\n",
    "## Expected Value\n",
    "We have:\n",
    "$$ E[X] = \\sum_{i=1}^{\\infty}x_iP(x_i) $$\n",
    "$$ = x_1\\cdotp p + x_2\\cdotp(1-p)p + x_3\\cdotp(1-p)^2p + x_4\\cdotp(1-p)^3p + ... $$\n",
    "$$ = p ( 1\\cdotp 1 + 2\\cdotp(1-p) + 3\\cdotp(1-p)^2 + 4\\cdotp(1-p)^3 + ...) $$\n",
    "$$ = p \\left(\\frac{1}{p^2}\\right) $$\n",
    "$$ = \\frac{1}{p} $$\n",
    "\n",
    "## Variance\n",
    "$$ Var(X) = \\frac{1-p}{p^2} $$\n",
    "\n",
    "The formula for variance can be derived/proved, but it isn't of much use to go through all the tedious derivation. Our work involves applying the formulas. In the future, there might be other probability distributions where we might welcome this abstraction of not having to derive the formulae, but putting them into use straight away."
   ],
   "metadata": {
    "id": "Mf2Yyjpu355n"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Negative Binomial Random Variable\n",
    "$X$ is a **Negative Binomial** random variable: $X \\sim NegBin(r, p)$\n",
    "<ul>\n",
    "  <li> $X$ is number of independent trials until r successes. </li>\n",
    "  <li> $p$ is the probability of success on each trial. </li>\n",
    "  <li> $X$ takes on the values $r, r+1, r+2, ..., $ with probability: </li>\n",
    "</ul>\n",
    "$$ P(X = n) = \\left(^{n-1}_{r-1}\\right)p^r(1-p)^{n-r}, \\qquad \\textrm{where } n = r, r+1, ..., $$\n",
    "The expected value can be given by:\n",
    "$$ E[X] = \\frac{r}{p} $$\n",
    "and the variance by:\n",
    "$$ Var(X) = \\frac{r(1-p)}{p^2} $$"
   ],
   "metadata": {
    "id": "BhA5fkkXmLOt"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Example: Dating\n",
    "Each person you date has a $0.2$ probability of being someone you spend your life with. What is the average number of people one will date? What is the standard deviation?\n",
    "\n",
    "Approach:\n",
    "After thinking about this, we come up with an assumption. The assumption is that the person you spend your life with is the last person you date. That is, after attaining one success, you don't conduct any other trials. Now, this could be transformed into a question that can be answered by the Geometric Random variable's mean, i.e. The weighted average of the number of independent trials until first success.\n",
    "\n",
    "$$E[X] = \\frac{1}{p} $$\n",
    "Therefore, you date $5$ people on average.\n",
    "\n",
    "The variance is:\n",
    "$$Var(X) = \\frac{1-p}{p^2} $$\n",
    "$$ = \\frac{0.8}{0.04} $$\n",
    "and it's square root, the standard deviation is $4.47$."
   ],
   "metadata": {
    "id": "qkxSxrmMoF5-"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Example: Equity in the courts\n",
    "### Berghuis v. Smith\n",
    "#### If a group is underrepresented in a jury pool, how do you tell?\n",
    "\n",
    "Justice Breyer opened the questioning by invoking the binomial theorem. He hypothesized a scenario involving **\"an urn with a thousand balls, and sixty are blue, and nine hundred forty are purple, and then you select them at random... twelve at a time.\"** According to Justice Breyer and the binomial theorem, if the purple balls were under represented jurors then **\"you would expect... something like a third to a half of juries would have at least one minority person\"** on them."
   ],
   "metadata": {
    "id": "iQVnNdwmpzSh"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Formulating a question\n",
    "If you select 12 balls out of 1000, of which 60 are purple and 940 are blue, what is the probability of you getting AT LEAST 1 ball.\n",
    "We can answer this question by calculating the probability of getting zero balls and taking the complement.\n",
    "i.e.\n",
    "$$ p(0) = \\frac{940}{1000}\\frac{939}{999}...$$"
   ],
   "metadata": {
    "id": "3sV-LS9jGA4Z"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "totalProb = 1\n",
    "for i in range(0, 12):\n",
    "  totalProb *= (940-i)/(1000-i)\n",
    "1-totalProb"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xMry7JBdGnBt",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1709697191620,
     "user_tz": -330,
     "elapsed": 4,
     "user": {
      "displayName": "Parshv Joshi",
      "userId": "11339326919544553803"
     }
    },
    "outputId": "eb421182-165e-4aec-f081-0969c6878230",
    "ExecuteTime": {
     "end_time": "2024-03-08T07:37:59.687766Z",
     "start_time": "2024-03-08T07:37:59.683728Z"
    }
   },
   "execution_count": 19,
   "outputs": [
    {
     "data": {
      "text/plain": "0.5260963453749402"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "This is a long shot from the **third to half**, that Breyer estimated. The probability is over half everytime.\n",
    "\n",
    "One more interesting thing is that we haven't studied any probability distribution that can be used here. Sure, you could use binomial, but notice that everytime you choose a person, the probability of the same type of person being chosen in the next turn decreases slightly. To combat this, we can use Hypergeometric distribution."
   ],
   "metadata": {
    "id": "8Voo5sDJHgRv"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Example: Bitcoin Mining\n",
    "While mining bitcoins, you are given a data, which is fixed, and you have to find a Salt (a choice that you make). You \"mine a bitcoin\" if, for given data $D$, you find a salt number $N$, such that $Hash(D, N)$ produces a string that starts with $g$ zeroes."
   ],
   "metadata": {
    "id": "3yJkoVT9Iba_"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<ol type = \"a\">\n",
    "  <li> What is the probability that the first number you try will produce a bit string which starts with $g$ zeres (in other words, you mine a bitcoin)? </li>\n",
    "  <li> What is the probability that you will need under $100$ attempts to mine $2$ bitcoins?"
   ],
   "metadata": {
    "id": "Y99xZnV5_ZAz"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Let $X$ be the number of zeros in the first $g$ bits.\n",
    "$$ X \\sim Bin(n = g, p = 0.5) $$\n",
    "The probability, then, of getting $0$ zeros in the first $g$ bits is:\n",
    "$$ P(X = 0) = \\left(^g_0\\right)\\frac{1}{2}^g = \\frac{1}{2}^g$$\n",
    "Now, for the probability that you will need under $100$ attempts for $2$ bitcoins:\n",
    "$$ X \\sim Bin(n = 100, p = \\frac{1}{2}^g) $$\n",
    "And, we answer the question by taking the complement of the probability that we mine $0$ or $1$ bitcoin in 100 trials."
   ],
   "metadata": {
    "id": "ySbug-YaAdK7"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "totalProb = 0\n",
    "for i in range(0, 2):\n",
    "  totalProb += scipy.stats.binom.pmf(i, 100, (0.5)**17)\n",
    "1-totalProb"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "E0kwDLCOCXCl",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1709697191620,
     "user_tz": -330,
     "elapsed": 3,
     "user": {
      "displayName": "Parshv Joshi",
      "userId": "11339326919544553803"
     }
    },
    "outputId": "1bdde970-cc4a-4618-9806-a9db66ba64fa",
    "ExecuteTime": {
     "end_time": "2024-03-08T07:38:00.977610Z",
     "start_time": "2024-03-08T07:38:00.972631Z"
    }
   },
   "execution_count": 20,
   "outputs": [
    {
     "data": {
      "text/plain": "2.8798434326127165e-07"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Continuous Random Variables and the Probability Density Function\n",
    "\n",
    "## Again, starting with an example\n",
    "\n",
    "Say the average rate of earthquakes is $1$ every $100$ years. \\\\\n",
    "We can talk about the probability distribution of different numbers of earthquakes next year. \\\\\n",
    "We can't talk about the probability distribution of the amount of time until the next earthquakes. This is because time is continuous. It doesn't make sense to have $3.5$ earthquakes in the next year, but it does make sense to say probability of an earthquakes in the next $3.5$ years.\n",
    "\n",
    "For this, we can break the x axis, where we have time, into smaller and smaller sections, until we have the derivative of Probability $f(T = t)$, and its value with time t.\n",
    "\n",
    "## Probability Density Function\n",
    "The probability density function (PDF) of a continuous random variable represents the relative likelihood of various values.\n",
    "\n",
    "Units of probability divided by units of $X$. **Integrate it** to get probabilities!\n",
    "\n",
    "$$P(a < X < b) = \\int_{x=a}^bf(X = x)dx $$\n",
    "\n",
    "This gives the probability of the event happening between time $a$ and time $b$.\n",
    "\n",
    "### Properties of PDFs\n",
    "The integral of a PDF gives a probability. Thus:\n",
    "$$ 0 \\leq \\int_{x=a}^{b}f(X = x)dx \\leq 1 $$\n",
    "$$ \\int_{x=-\\infty}^{\\infty}f(X = x)dx = 1 $$\n",
    "Probability density functions articulate _relative_ belief. \\\\\n",
    "PDF has the \"units\" of: **probability divided by units of $X$** \\\\\n",
    "$X$ can be time, X can also be space (as in quantum mechanics).\n"
   ],
   "metadata": {
    "id": "p4J0_0dtE6tl"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Uniform Random Variable\n",
    "A **uniform** random variable is **equally likely** to be any value in an interval.\n",
    "$$ X \\sim Uni(\\alpha, \\beta) $$\n",
    "Here, the lowest value it can take is $\\alpha$, and the highest value it can take is $\\beta$, and $X$ has equal probability of taking any of the values between $\\alpha$ and $\\beta$. \\\\\n",
    "$$ n_o(a)=  \\left\\{\n",
    "\\begin{array}{ll}\n",
    "      \\frac{1}{\\beta - \\alpha}, \\qquad \\alpha \\leq x \\leq \\beta\\\\\n",
    "      0, \\qquad \\textrm{otherwise} \\\\\n",
    "\\end{array}\n",
    "\\right. $$"
   ],
   "metadata": {
    "id": "Utmzf210JH1d"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Exponential Random Variable\n",
    "Consider an experiment that lasts a duration of time until success occurs.\n",
    "**An exponential random variable $X$ is the amount of time until success.**\n",
    "$$ X \\sim Exp(\\lambda) $$\n",
    "$$ f(x) = \\left\\{\\begin{array}{ll}\n",
    "  \\lambda e^{-\\lambda x}, \\qquad \\textrm{if } x \\geq 0 \\\\\n",
    "  0, \\qquad \\textrm{otherwise}\n",
    "\\end{array} \\right.\n",
    "$$\n",
    "$$ E[X] = \\frac{1}{\\lambda} $$\n",
    "$$ Var(X) = \\frac{1}{\\lambda^2} $$\n",
    "\n",
    "## Example\n",
    "Based on historical data, major earthquakes (magnitude $8.0$+) happen at a **rate of $0.002$** per year. What is the probability of a major earthquake in the next 30 years?\\\\\n",
    "$Y$ = Years until the next earthquake of magnitude $8.0$+.\n",
    "$$Y \\sim Exp(\\lambda = 0.002) $$\n",
    "$$ f_Y(y) = \\lambda e^{-\\lambda y}$$\n",
    "$$ = 0.002^{-0.002y} $$\n",
    "$$ P(Y < 30) = \\int_0^{30}0.002^{-0.002y}dy $$\n",
    "$$ = 0.06 $$\n",
    "\n",
    "What is the exptected number of years until the next earthquake?\n",
    "$$500$$\n",
    "\n",
    "# Cumulative Density Function\n",
    "A cumulative density function (CDF) is a \"closed form\" equation for the probability that a random variable is less than a given value\n",
    "$$ F(x) = P(X < x)$$\n",
    "or $$F_X(x)$$\n",
    "\n",
    "## CDF of an exponential\n",
    "$$ F_X(x) = 1-e^{-\\lambda x} $$\n",
    "Derivation idea:\n",
    "$$ P(X < x) = \\int_{y = 0}^{x}\\lambda e^{-\\lambda y}dy $$"
   ],
   "metadata": {
    "id": "Kixz6fhmLPYG"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Normal Random Variable\n",
    "A **Normal** random variable $X$ is defined as follows:\n",
    "$$ X \\sim \\mathcal{N}(\\mu,\\,\\sigma^2)$$\n",
    "$$ E[X] = \\mu $$\n",
    "$$ Var(X) = \\sigma^2 $$\n",
    "$$ f(x) = \\frac{1}{\\sigma \\sqrt{2\\pi}}e^{-(x-\\mu)^2/2\\sigma^2}$$\n",
    "Why the normal?\n",
    "<ul>\n",
    "  <li> Common for natural phenomena: height, weight, etc. </li>\n",
    "  <li> Most noise in the world is Normal </li>\n",
    "  <li> Often results from the sum of many random variables </li>\n",
    "  <li> Sample means are distributed normally </li>\n",
    "</ul>"
   ],
   "metadata": {
    "id": "5LGcFVYNSXAC"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "But, these are not really gaussian (normal), pretty close though. So, that begs the question, why do we use the normal distribution to assume many natural phenomena? \\\\\n",
    "The answer is that if you know the mean of your data, and you know the standard deviation of your data, the normal distribution is observed to be the closest distribution to the one that fits the data perfectly. It turns out that they are also easy to use.\n",
    "\n",
    "## Anatomy of the Gaussian Equation\n",
    "$$\\mathcal{N}(\\mu,\\,\\sigma^2)$$\n",
    "$$f(x) = \\frac{1}{\\sigma\\sqrt{2\\pi}}e^\\frac{-(x-\\mu)^2}{2\\sigma^2}$$\n",
    "\n",
    "## Cumulative Density Function\n",
    "It turns out that the Gaussian distribution is non-integrable. Thus, we have made a lookup table for a special Gaussian Distribution, with $\\mu = 0$ and $\\sigma = 1$. This is called the standard normal distribution. \\\n",
    "For the standard normal distribution, if we have any random variable $X$, we can rewrite $Z = \\frac{X-\\mu}{\\sigma}$. \\\n",
    "As we can't have an expression for CDF, instead, we have the Greek symbol $\\Phi$ to represent the CDF, which outputs the values we already rigorously computed.\n",
    "$$P(X \\leq x) = \\Phi(\\frac{x-\\mu}{\\sigma})$$"
   ],
   "metadata": {
    "id": "dQpflF2YUsbQ"
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "id": "NX8wqTNk79VP"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Example: Enough Servers?\n",
    "You are running a website, Alibayes\n",
    "You want to buy computers based on usage at the busiest minute. \n",
    "You receive $R \\sim \\mathcal{N}(\\mu = 10^6, \\sigma = 10^4 $ requests at the busiest minute.\n",
    "\n",
    "You are going to buy k servers.\n",
    "Each server can handle 10,000 requests per minute, otherwise you drop requests. What is the smallest value of k such that P(No Drops) > 0.9999?\n",
    "\n",
    "We have to find k such that $P(R < 10^4k) = 0.9999$\n",
    "$$P(R < 10^4k) = \\Phi\\left(\\frac{10^4k-10^6}{10^4}\\right) $$\n",
    "$$ \\Phi(k - 100)  = 0.9999$$\n",
    "$$ k = \\Phi^{-1}(0.9999) + 100 $$"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "103.71901648545571"
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scipy.stats.norm.ppf(0.9999) + 100"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-08T07:38:41.475180Z",
     "start_time": "2024-03-08T07:38:41.468142Z"
    }
   },
   "execution_count": 21
  },
  {
   "cell_type": "markdown",
   "source": [
    "$$ \\log(a\\cdotp b) = log(a) + log(b)$$"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ]
}
